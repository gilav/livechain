import json
import os,sys,traceback,time
import shutil
from datetime import datetime
from pathlib import Path
import multiprocessing as mp
#from multiprocessing import Manager, Value
import threading
import re

#
import configuration
from interfaces.iKillable import iKillable
from process.iProcessor import iProcessor
#
from persistqueue import FIFOSQLiteQueue
from configuration import Configuration
#
import db.dbLayer as dbLayer
from models.products import SourceProduct, EoSipProduct
#
from wrapper import eoSipConverterWrapper
from wrapper.eoSipConverterWrapper import EoSipConverterWrapper
from helpers.stdCapture import Capture
#
from eosip.eosipValidator import Landsat8InputValidator
#
from notification.redisLPublisher import RedisPublisher
from workflow.mover import Mover
import myLoggerConfig

#
COMPONENT='live-chain_EoSipHandler'

#
DEFAULT_CHARSET='UTF-8'
#
MAX_PROCESSES=4
#
SUPRESS_CONVERTER_STDS=True
#
REF_BASENAME='LC08_L1GT_193024_20210629_20210629_02_RT'
SRC_PATH='src_path'
currentdir = os.path.dirname(os.path.abspath(eoSipConverterWrapper.__file__))

debug=False

#
# the pool worker
#
def worker(con):
	#self.logger.info(f"worker({os.getpid()}) working...") # (con:{dir(con)})")
	while True:
		#item = queue.get(True)
		item = con.q.get(True)
		#self.logger.debug(f"worker({os.getpid()}) got {item}")
		#time.sleep(5) # simulate a "long" operation
		con.c.makeOneEosip(item)

# context passed to pool worker
class Context():
	q=None
	c=None


#
#
#
class EoSipHandler(threading.Thread, iProcessor, iKillable):

	def __init__(self,  pQueue: FIFOSQLiteQueue, config: Configuration):
		threading.Thread.__init__(self)
		self.logger = myLoggerConfig.applyLoggingLevel(self.__class__.__name__, True)
		self.pub = RedisPublisher()
		current_time = str(datetime.now())
		self.pub.publish(COMPONENT, f"{COMPONENT} started at {current_time}")
		#
		self.lock = mp.Lock()
		self.inputItemsDone = mp.Manager().list()
		self.total= mp.Value('i', 0)
		self.failed = mp.Value('i', 0)
		#self.invalid:int=0
		self.queued:int=0
		self.config = config
		#
		self.pending = mp.Value('i', 0)
		self.running:bool=False
		self.displayWait:bool=False
		self.pQueue = pQueue #FIFOSQLiteQueue(path=self.queuePath, multithreading=True)
		#
		self.mover = Mover()
		self.logger.info(f"__init__ done")

	#
	#
	#
	def oneDone(self, item):
		self.total.value+=1
		self.pending.value-=1
		self.displayWait=True
		if debug:self.logger.debug(f"one done: {item[SRC_PATH]}")
		self.logSummary()

	#
	#
	#
	def oneFailed(self, item):
		self.failed.value+=1
		self.pending.value-=1
		self.displayWait=True
		if debug:self.logger.debug(f"one failed: {item[SRC_PATH]}")
		self.logSummary()

	#
	#
	#
	def logSummary(self):
		self.logger.info(f"waiting (queued:{self.queued}; pending:{self.pending.value}; done:{self.total.value}; failed:{self.failed.value})...")
		self.pub.publish(COMPONENT, f"Item(s) queued:{self.queued}; pending:{self.pending.value}; done:{self.total.value}; failed:{self.failed.value}")
		self.displayWait = False

	#
	#
	#
	def status(self)->str:
		return f"Item(s) queued:{self.queued}; pending:{self.pending.value}; done:{self.total.value}; failed:{self.failed.value}"

	#
	#
	#
	def run(self):
		self.working=True
		# create multiprocessing queue
		self.workerQueue = mp.Queue()
		# will be passed as arg to pool worker
		con=Context()
		con.q=self.workerQueue
		con.c=self
		# create multiprocessing pool
		self.pool = mp.Pool(MAX_PROCESSES, worker, (self.workerQueue,))
		#self.pool = Manager().Pool(MAX_PROCESSES, worker, (con,))
		self.logger.info(f"run: multiprocessing stuff set")

		#
		self.running=True
		if debug:
			self.logger.info(f"running...")

		self.displayWait = False
		while self.running:
			if self.pQueue.size() > 0:
				self.queued=self.pQueue.size()
				self.logger.debug(f" #### number of items queued: {self.queued}")
				while self.pQueue.size()>0:
					item=self.pQueue.get()
					ok, mission = self.validate(item)
					if ok:
						item['mission']=mission
						self.workerQueue.put(item)
						self.logger.debug(f" #### item added to worker queue: {item}")
						self.pending.value+=1
						self.displayWait = True
					else:
						self.logger.debug(f" #### item not validated: {item}")
			else:
				self.queued=0
				if self.displayWait:
					self.logSummary()
				time.sleep(2)

		if debug:
			self.logger.info(f"!! terminated")

	#
	# validate the input:
	# - get the mission from path
	# - landsat8: use specific validator
	#
	def validate(self, item):
		self.logger.debug(f"validate {item[SRC_PATH]}")
		mission = self.config.resolveInboxToMission(item[SRC_PATH])
		self.logger.debug(f"validate: {item[SRC_PATH]} mission: {mission}")
		if mission is not None:
			# specific validator, return .tar input even if the input was a .jpg (when all pieces are there and ok)
			validator = Landsat8InputValidator()
			validated, inputTar = validator.validateLandsat8Input(item)
			if inputTar != item[SRC_PATH]:
				item[SRC_PATH]=inputTar
			return validated, mission
		return False, None

	#
	# Processor interface: unused
	#
	def process(self, **kwargs):
		if 'eosip' in kwargs:
			self.logger.debug(f" process eosip:{kwargs['eosip']}")
		else:
			self.logger.warning(f" process: no eosip in kwargs!")

	#
	#
	#
	def setInputDone(self, value):
		self.lock.acquire()
		try:
			with self.inputItemsDone.mutex:
				return list(self.base_queue.queue)
		except Exception as e:
			print(f" ERROR getting MemoryQueue values:{str(e)}")
		finally:
			self.lock.release()
	#
	#
	#
	def makeOneEosip(self, item):
		self.logger.info(f" ####### makeOneEosip; item:{item}")
		self.pub.process(mesg=f" makeOneEosip; item:{item[SRC_PATH]}")
		doneDict=None
		try:
			self.logger.info(f"worker doing item: {item[SRC_PATH]}")

			# already done?
			print(f" ########################################### makeOneEosip; self.inputItemsDone:{self.inputItemsDone}")
			if item[SRC_PATH] in self.inputItemsDone:
				self.logger.info(f" @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ makeOneEosip; item:{item[SRC_PATH]} ALREADY DONE")
				return
			print(f" ########################################### makeOneEosip; add in self.inputItemsDone:{item[SRC_PATH]}")
			self.inputItemsDone.append(item[SRC_PATH])

			dbId = self.addInSourceTable(item)
			#
			exitCode, doneFlagFile = self.runWrapper(item, dbId)
			with open(doneFlagFile, 'rb') as fd:
				doneDict = json.load(fd)
			self.logger.info(f"worker wrapper exitCode: {exitCode}; doneFlagFile: {doneFlagFile}")
			#
			item['doneFlagFile']=doneFlagFile
			#
			if exitCode==0:
				if doneDict['state']=='SUCCESS':
					self.logger.info(f"====>> item: {item[SRC_PATH]} done")
					self.pub.publish(COMPONENT, f" makeOneEosip; item:{item[SRC_PATH]} done")
					self.oneDone(item)
				else:
					print(" TODO: control what returns the wrapper iwhen exitCode !=0: wrapper error or converter exit code??")
					#os._exit(1)
					self.logger.error(f"====>> item: {item[SRC_PATH]} failed, error: {doneDict['error']}")
					self.pub.publish(COMPONENT, f" makeOneEosip; item:{item[SRC_PATH]} failed, error: {doneDict['error']}")
					self.oneFailed(item)
			else:
				self.logger.error(f"====>> item: {item[SRC_PATH]} failed, error: {doneDict['error']}")
				self.pub.publish(COMPONENT, f" makeOneEosip; item:{item[SRC_PATH]} failed, error: {doneDict['error']}")
				self.oneFailed(item)

			# move input files out of inbox
			self.moveInputs(item, exitCode)
			#
			self.updateProductTables(item, dbId, exitCode)
		except Exception as e:
			self.oneFailed(item)
			exc_type, exc_obj, exc_tb = sys.exc_info()
			self.logger.error(f"Error {exc_type} {exc_obj}")
			traceback.print_exc(file=sys.stdout)

	#
	#
	#
	def addInSourceTable(self, item):
		session = dbLayer.Session()
		r = SourceProduct()
		r.filename=os.path.basename(item[SRC_PATH])
		r.fullpath=item[SRC_PATH]
		r.at=time.time()
		r.size=os.stat(item[SRC_PATH]).st_size
		session.add(r)
		session.commit()
		dbId = r.id
		self.logger.debug(f" addInSourceTable; item:{item} has id:{dbId}")
		return dbId

	#
	#
	#
	def addInEosipsTable(self, item, srcDbId, doneDict, session):
		r = EoSipProduct()
		r.at=time.time()
		r.fullpath=doneDict['eosip']
		r.filename=os.path.basename(doneDict['eosip'])
		r.size=doneDict['eosipSize']
		r.hashkey=doneDict['eosipMd5']
		session.add(r)
		session.commit()
		dbId = r.id
		self.logger.debug(f" addInEosipsTable; item:{item} has id:{dbId}")
		return dbId


	#
	# update tables:
	# - input table
	# - eosip table in case of success
	#
	def updateProductTables(self, item, srcDbId, exitCode):
		session = dbLayer.Session()
		# update input table
		recs = session.query(SourceProduct).filter(SourceProduct.id == srcDbId).all()
		self.logger.debug(f" updateProductTables; query SourceProduct[id={srcDbId}]: {recs}")
		if len(recs)==1:
			with open(item['doneFlagFile'], 'rb') as fd:
				doneDict = json.load(fd)
			# both failure and success
			recs[0].eosipdoneat=time.time()
			if exitCode!=0:
				recs[0].comment=doneDict['error']
				session.commit()
			else:
				if 'doneFlagFile' not in item:
					raise Exception("no doneFlagFile in item after conversion ok.")
				self.logger.debug(f" updateProductTables; loading doneFlagFile[{srcDbId}] content from file: {item['doneFlagFile']}")
				self.logger.debug(f" updateProductTables; doneDict: {doneDict}")
				recs[0].eosipdone=True
				recs[0].eosipname=os.path.basename(doneDict['eosip'])
				recs[0].eosiphashkey=doneDict['eosipMd5']
				#
				self.addInEosipsTable(item, srcDbId, doneDict, session)

		else:
			self.logger.error(f" updateProductTables; query SourceProduct[id={srcDbId}] return nothing")




	#
	# doneFlagFile is json
	#
	def runWrapper(self, item, dbId:int):
		self.logger.debug(f" runWrapper; item:{item[SRC_PATH]}")
		ingesterInstance = self.config.missionConfig[item['mission']][configuration.SETTING_CONVERTER]
		converterConfigPath = f"{currentdir}/{self.config.missionConfig[item['mission']][configuration.SETTING_CONVERTER_CONFIG]}"
		doneFlagFile = f"{self.config.missionConfig[item['mission']][configuration.SETTING_TMPSPACE]}/doneFile_{dbId}.json"
		tmpFolder = f"{self.config.missionConfig[item['mission']][configuration.SETTING_TMPSPACE]}/{dbId}"
		args={'-i':str(0),
			  '-t':tmpFolder,
			  '-o':self.config.missionConfig[item['mission']][configuration.SETTING_OUTBOX],
			  '-s': item[SRC_PATH],
			  }
		self.logger.debug(f" runWrapper; args:{args}")
		now = time.time()
		# keep old stds
		old_stdout = None
		old_stderr = None
		if SUPRESS_CONVERTER_STDS:
			old_stdout = sys.stdout
			old_stderr = sys.stderr
			sys.stdout = Capture(sys.stdout, None, True)
			sys.stderr = Capture(sys.stderr, None, True)
		#self.logger.disabled = True
		#logging.getLogger('root').disabled = True
		w = EoSipConverterWrapper(ingesterInstance, converterConfigPath, doneFlagFile, now)
		exitCode = w.start(args)
		#self.logger.disabled = False
		#logging.getLogger('root').disabled = False
		if SUPRESS_CONVERTER_STDS:
			fd = open(f"{tmpFolder}/stdout.txt", 'w')
			fd.write(sys.stdout.getStdAll())
			fd.flush()
			fd.close()
			fd = open(f"{tmpFolder}/stderr.txt", 'w')
			fd.write(sys.stderr.getStdAll())
			fd.flush()
			fd.close()
			sys.stdout = old_stdout
			sys.stderr = old_stderr
		mesg=None
		if exitCode!=0: # wrapper ok? ir does the wrapper returns the converter exit code??

			# doneFlagFile statu==SUCESS/FAILURE xxx
			"""
			now json:
			{
			   "orchestrator":"?",
			   "id":"doneFile_2",
			   "at":0.7847530841827393,
			   "time":1633989847.5772767,
			   "processingTime":0.2733008861541748,
			   "exitCode":-1,
			   "state":"FAILURE Exception: product has bad extension, expected .tar:'/home/gilles/shared/converters/live_chain_INBOX/LC08_L1GT_193024_20210629_20210629_02_RT_QB.jpg",
			   "error":"Exception: product has bad extension, expected .tar:'/home/gilles/shared/converters/live_chain_INBOX/LC08_L1GT_193024_20210629_20210629_02_RT_QB.jpg",
			   "source":"/home/gilles/shared/converters/live_chain_INBOX/LC08_L1GT_193024_20210629_20210629_02_RT_QB.jpg"
			}
			
			{
			   "orchestrator":"?",
			   "id":"doneFile_31",
			   "at":0.9359545707702637,
			   "time":1634035568.7110653,
			   "ctime":"Tue 2021/10/12 12:46:06",
			   "processingTime":0.5973527431488037,
			   "exitCode":0,
			   "state":"SUCCESS",
			   "source":"/home/gilles/shared/converters/live_chain_INBOX/LC08_L1GT_193024_20210629_20210629_02_RT.tar",
			   "sourceSize":32256,
			   "sourceMd5":"486374b3893d1a9c4bb442cc75477fff",
			   "eosip":"/home/gilles/shared/converters/live_chain_OUTBOX/L08_ORCL_OAT_GEO_1P_20210629T100250_20210629T100250_000000_0193_0024_00_v0101.SIP.ZIP",
			   "eosipSize":4541796,
			   "eosipMd5":"6f96529e1cc030da804eec7f9d1205b5"
			}
			"""
		return exitCode, doneFlagFile

	#
	# move processed inputs
	#
	def moveInputs(self, anItem, exitCode):
		if debug:print(f"move item: {anItem[SRC_PATH]} to dest")
		try:
			if exitCode==0:
				srcbase = self.config.missionConfig[anItem['mission']][configuration.SETTING_INBOX]
				if debug:print(f"srcbase: {srcbase}")
				src = os.path.dirname(anItem[SRC_PATH])
				relPath = src[len(srcbase):]
				if debug:print(f"relPath: {relPath}")
				#dest = os.path.join(self.config.missionConfig[anItem['mission']][configuration.SETTING_DONESPACE], relPath)
				dest = self.config.missionConfig[anItem['mission']][configuration.SETTING_DONESPACE] + relPath
				if not os.path.exists(dest):
					if debug:print(f"will create dest folder0: {dest}")
					#os._exit(1)
					os.makedirs(dest)
				if debug:print(f"move inputs ok from {src} to {dest}")
				for item in anItem['eoProductContent']:
					shutil.move(os.path.join(src, item), os.path.join(dest, item))
					#print(f" ############ shutil.move {os.path.join(src, item)} to {os.path.join(dest, item)}")
			else:
				srcbase = self.config.missionConfig[anItem['mission']][configuration.SETTING_INBOX]
				if debug:print(f"srcbase: {srcbase}")
				src = os.path.dirname(anItem[SRC_PATH])
				relPath = src[len(srcbase):]
				if debug:print(f"relPath: {relPath}")
				#dest = os.path.join(self.config.missionConfig[anItem['mission']][configuration.SETTING_DONESPACE], relPath)
				dest = self.config.missionConfig[anItem['mission']][configuration.SETTING_DONESPACE] + relPath
				if not os.path.exists(dest):
					if debug:print(f"will create dest folder1: {dest}")
					#os._exit(1)
					os.makedirs(dest)
				if debug:print(f"move inputs failed from {src} to {dest}")
				for item in anItem['eoProductContent']:
					shutil.move(os.path.join(src, item), os.path.join(dest, item))
					#print(f" ############ shutil.move {os.path.join(src, item)} to {os.path.join(dest, item)}")
		except Exception as e:
			self.logger.error(f"Error moving inputs: {e}")
			traceback.print_exc(file=sys.stdout)
			#os._exit(1)

